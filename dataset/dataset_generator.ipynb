{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30f59be0-2bfe-4284-8709-cf7d3db42534",
   "metadata": {},
   "source": [
    "## Dataset Generator\n",
    "\n",
    "> @ Author: Chen Wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "164f8eaa-fdc3-4934-8c88-47e7915c24a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 18:48:33.097085: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os, copy, itertools, csv\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fcd5fbf-2ca5-4832-9702-84ba59d3dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_rect_and_landmark_points(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "    landmark_points = []\n",
    "    \n",
    "    for landmark in landmarks[0].landmark:\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        landmark_point = [landmark_x, landmark_y]\n",
    "        landmark_points.append(landmark_point)\n",
    "        \n",
    "    x, y, w, h = cv.boundingRect(np.array(landmark_points))\n",
    "    return [x, y, x+w, y+h], landmark_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "222fa846-db4c-457d-8881-e19ed5b500a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_landmark(landmark_points):\n",
    "    temp_landmark_points = copy.deepcopy(landmark_points)\n",
    "    \n",
    "    # Convert to relative coordinates\n",
    "    base_x = temp_landmark_points[0][0]\n",
    "    base_y = temp_landmark_points[0][1]\n",
    "    \n",
    "    index = 1\n",
    "    for landmark_point in temp_landmark_points[1:]:\n",
    "        temp_landmark_points[index][0] = temp_landmark_points[index][0] - base_x\n",
    "        temp_landmark_points[index][1] = temp_landmark_points[index][1] - base_y\n",
    "        index += 1\n",
    "    \n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_points = list(itertools.chain.from_iterable(temp_landmark_points))\n",
    "    \n",
    "    # normalize list\n",
    "    max_value = max(temp_landmark_points, key=abs)\n",
    "    temp_landmark_points = list(map(lambda x: x/max_value, temp_landmark_points))\n",
    "    \n",
    "    return temp_landmark_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44a8b945-e184-4802-afcd-1507aa4cb80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/hand-gesture-recognition-mediapipe'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "root_path = os.getcwd()\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "10574c32-498b-49af-9c34-405388efb790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_name: call\n",
      "class_name: dislike\n",
      "class_name: fist\n",
      "class_name: four\n",
      "class_name: like\n",
      "class_name: mute\n",
      "class_name: ok\n",
      "class_name: one\n",
      "class_name: stop_inverted\n",
      "class_name: rock\n",
      "class_name: peace_inverted\n",
      "class_name: stop\n",
      "class_name: palm\n",
      "class_name: peace\n",
      "class_name: three\n",
      "class_name: three2\n",
      "class_name: two_up\n",
      "class_name: two_up_inverted\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(root_path, \"dataset/ori_dataset\")\n",
    "\n",
    "# csv_data_path = os.path.join(root_path, \"dataset/keypoint.csv\")\n",
    "# csv_data_file = open(csv_data_path, \"w\", newline=\"\")\n",
    "# csv_data_writer = csv.writer(csv_data_file)\n",
    "\n",
    "csv_label_path = os.path.join(root_path, \"dataset/keypoint_classifier_label.csv\")\n",
    "csv_label_file = open(csv_label_path, \"w\", newline=\"\")\n",
    "csv_label_writer = csv.writer(csv_label_file)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5)\n",
    "\n",
    "class_name = None\n",
    "class_index = -1\n",
    "for root, dirs, files in os.walk(dataset_path, topdown=False):\n",
    "    if root.endswith(\".ipynb_checkpoints\") or root.endswith(\"dataset\"):\n",
    "            continue\n",
    "    for file in files:\n",
    "        if file.startswith(\".\"): continue\n",
    "        new_class_name = root.split(\"/\")[-1]\n",
    "        if class_name != new_class_name:\n",
    "            class_name = new_class_name\n",
    "            print(\"class_name: {}\".format(class_name))\n",
    "            class_index += 1\n",
    "            csv_label_writer.writerow([class_name])\n",
    "        \n",
    "        file_path = os.path.join(root, file)\n",
    "        image = cv.imread(file_path)\n",
    "        flip_image = cv.flip(image, 1)\n",
    "        debug_image = copy.deepcopy(flip_image)\n",
    "        rgb_image = cv.cvtColor(flip_image, cv.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb_image)\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            hand_landmarks = results.multi_hand_landmarks\n",
    "            handedness = results.multi_handedness\n",
    "            brect, landmark_points = get_bounding_rect_and_landmark_points(debug_image, hand_landmarks) # [x, y, x+w, y+h], landmark_points\n",
    "            pre_processed_landmark_points = pre_process_landmark(landmark_points)\n",
    "            csv_data_writer.writerow([class_index, *pre_processed_landmark_points])\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ced4b039-6151-4837-823a-88355b3307d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_loader():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49b7a61d-b6a6-4076-9663-7d342df5add4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118245f7-a5e7-4b12-a9bf-9e73808cabbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}